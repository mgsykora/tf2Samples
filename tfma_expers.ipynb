{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam  \n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "from tensorflow_transform.coders import example_proto_coder\n",
    "from tensorflow_transform.saved import saved_transform_io\n",
    "from tensorflow_transform.tf_metadata import dataset_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit the following, **replacing `<YOUR_BUCKET_PATH>` and `<WORKFLOW_NAME>` with the correct values**.  You can find the name of a given workflow by looking at the `argo submit` output, or in the Argo UI.  The workflow name is also reflected in the Kubernetes pod names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH_PREFIX = 'gs://<YOUR_BUCKET_PATH>/<WORKFLOW_NAME>/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Error executing an HTTP request: HTTP response code 400 with body '{\n  \"error\": {\n    \"code\": 400,\n    \"message\": \"Invalid bucket name: '\\u003cYOUR_BUCKET_PATH\\u003e'\",\n    \"errors\": [\n      {\n        \"message\": \"Invalid bucket name: '\\u003cYOUR_BUCKET_PATH\\u003e'\",\n        \"domain\": \"global\",\n        \"reason\": \"invalid\"\n      }\n    ]\n  }\n}\n'\n\t when reading metadata of gs://<YOUR_BUCKET_PATH>/<WORKFLOW_NAME>/tfma/output/eval_config.json",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-116ee4f81308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m tfma_result1 = tfma.load_eval_result(\n\u001b[0;32m----> 2\u001b[0;31m     output_path= OUTPUT_PATH_PREFIX + 'tfma/output')\n\u001b[0m\u001b[1;32m      3\u001b[0m tfma_result2 = tfma.load_eval_result(\n\u001b[1;32m      4\u001b[0m     output_path=OUTPUT_PATH_PREFIX + 'tfma2/output')\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_model_analysis/api/model_eval_lib.py\u001b[0m in \u001b[0;36mload_eval_result\u001b[0;34m(output_path, model_name)\u001b[0m\n\u001b[1;32m    197\u001b[0m                      model_name: Optional[Text] = None) -> EvalResult:\n\u001b[1;32m    198\u001b[0m   \u001b[0;34m\"\"\"Creates an EvalResult object for use with the visualization functions.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m   \u001b[0meval_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_eval_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m   \u001b[0moutput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output_data_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m   metrics_proto_list = (\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_model_analysis/api/model_eval_lib.py\u001b[0m in \u001b[0;36mload_eval_config\u001b[0;34m(output_path)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;34m\"\"\"Loads eval config.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_EVAL_CONFIG_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m       \u001b[0mpb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvalConfigAndVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mfile_exists_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    278\u001b[0m   \"\"\"\n\u001b[1;32m    279\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileExists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Error executing an HTTP request: HTTP response code 400 with body '{\n  \"error\": {\n    \"code\": 400,\n    \"message\": \"Invalid bucket name: '\\u003cYOUR_BUCKET_PATH\\u003e'\",\n    \"errors\": [\n      {\n        \"message\": \"Invalid bucket name: '\\u003cYOUR_BUCKET_PATH\\u003e'\",\n        \"domain\": \"global\",\n        \"reason\": \"invalid\"\n      }\n    ]\n  }\n}\n'\n\t when reading metadata of gs://<YOUR_BUCKET_PATH>/<WORKFLOW_NAME>/tfma/output/eval_config.json"
     ]
    }
   ],
   "source": [
    "tfma_result1 = tfma.load_eval_result(\n",
    "    output_path= OUTPUT_PATH_PREFIX + 'tfma/output')\n",
    "tfma_result2 = tfma.load_eval_result(\n",
    "    output_path=OUTPUT_PATH_PREFIX + 'tfma2/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfma.view.render_slicing_metrics(\n",
    "    tfma_result1, slicing_column='trip_start_hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfma.view.render_slicing_metrics(\n",
    "    tfma_result2, slicing_column='trip_start_hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# An empty slice spec means the overall slice, that is, the whole dataset.# An em \n",
    "OVERALL_SLICE_SPEC = tfma.SingleSliceSpec()\n",
    "\n",
    "# Data can be sliced along a feature column\n",
    "# In this case, data is sliced along feature column trip_start_hour.\n",
    "FEATURE_COLUMN_SLICE_SPEC = tfma.SingleSliceSpec(columns=['trip_start_hour'])\n",
    "\n",
    "# Data can be sliced by crossing feature columns\n",
    "# In this case, slices are computed for trip_start_day x trip_start_month.\n",
    "FEATURE_COLUMN_CROSS_SPEC = tfma.SingleSliceSpec(columns=['trip_start_day', 'trip_start_month'])\n",
    "\n",
    "# Metrics can be computed for a particular feature value.\n",
    "# In this case, metrics is computed for all data where trip_start_hour is 12.\n",
    "FEATURE_VALUE_SPEC = tfma.SingleSliceSpec(features=[('trip_start_hour', 12)])\n",
    "\n",
    "# It is also possible to mix column cross and feature value cross.\n",
    "# In this case, data where trip_start_hour is 12 will be sliced by trip_start_day.\n",
    "COLUMN_CROSS_VALUE_SPEC = tfma.SingleSliceSpec(columns=['trip_start_day'], features=[('trip_start_hour', 12)])\n",
    "\n",
    "ALL_SPECS = [\n",
    "    OVERALL_SLICE_SPEC,\n",
    "    FEATURE_COLUMN_SLICE_SPEC, \n",
    "    FEATURE_COLUMN_CROSS_SPEC, \n",
    "    FEATURE_VALUE_SPEC, \n",
    "    COLUMN_CROSS_VALUE_SPEC    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show metrics sliced by COLUMN_CROSS_VALUE_SPEC above.\n",
    "tfma.view.render_slicing_metrics(tfma_result1, slicing_spec=COLUMN_CROSS_VALUE_SPEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show overall metrics.\n",
    "tfma.view.render_slicing_metrics(tfma_result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show overall metrics.\n",
    "tfma.view.render_slicing_metrics(tfma_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results in a Time Series. In this case, we are showing the slice specified.\n",
    "eval_results_from_disk = tfma.load_eval_results([\n",
    "    OUTPUT_PATH_PREFIX + 'tfma/output', \n",
    "    OUTPUT_PATH_PREFIX + 'tfma2/output'\n",
    "], \n",
    "                                                tfma.constants.MODEL_CENTRIC_MODE)\n",
    "tfma.view.render_time_series(eval_results_from_disk, FEATURE_VALUE_SPEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2018 Google Inc. All Rights Reserved.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
